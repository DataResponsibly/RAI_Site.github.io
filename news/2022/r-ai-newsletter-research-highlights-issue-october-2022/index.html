<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Sample News Post | Center for Responsible AI</title>
    <meta name="author" content="Center for Responsible AI">
    <meta name="description" content="march &amp; april, looking forward to summer">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css"
        integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css"
        integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css"
        integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css"
        href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media=""
        id="highlight_theme_light">
    <link rel="shortcut icon"
        href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://rai_lab.github.io/news/2023/formatting-and-links/">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css"
        media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
</head>

<body class="fixed-top-nav ">
    <header>
        <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
            <div class="header-image"></div>
            <div class="container">
                <div style="height: 100%"><a href="/"><img src="https://i.ibb.co/ZJ0tqjG/rai.png" alt="logo"></a></div>
                <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse"
                    data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false"
                    aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span
                        class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span
                        class="icon-bar bottom-bar"></span> </button>
                <div class="collapse navbar-collapse text-right" id="navbarNav">
                    <ul class="navbar-nav ml-auto flex-nowrap">
                        <li class="nav-item "> <a class="nav-link" href="/">about</a> </li>
                        <li class="nav-item "> <a class="nav-link" href="/blog/">news & events</a> </li>
                        <li class="nav-item "> <a class="nav-link" href="/resources/">resources</a> </li>
                        <li class="nav-item "> <a class="nav-link" href="/work/">work</a> </li>
                        <li class="nav-item "> <a class="nav-link" href="/people/">people</a> </li>
                        <li class="nav-item "> <a class="nav-link" href="/research/">research</a> </li>
                        <li class="nav-item "> <a class="nav-link" href="/education/">education</a> </li>
                        <li class="nav-item "> <a class="nav-link" href="/policy/">policy</a> </li>
                        <li class="nav-item "> <a class="nav-link" href="/events/">events</a> </li>
                        <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i
                                    class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li>
                    </ul>
                </div>
            </div>
        </nav> <progress id="progress" value="0">
            <div class="progress-container"> <span class="progress-bar"></span> </div>
        </progress>
    </header>
    <!-- DO NOT EDIT ANYTHING ABOVE THIS LINE-->



    <div class="container mt-5">
        <div class="post">
            <header class="post-header">
                <!-- Article heading-->
                <h1 class="post-title">R/AI Newsletter: Research Highlights Issue, October 2022</h1>
                <!-- Article author -->
                <p class="post-meta">By Oorja Pal</p>
                <!-- Date here -->
                <p class="post-tags"><i class="fas fa-calendar fa-sm"></i> &nbsp; February 15, 2023</p>
            </header>
            <article class="post-content">
                <!-- Normal style content to be posted below -->
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    <b>Personality prediction AI used for pre-hiring screening is shockingly bad! </b>
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    Our research team recently audited two popular commercial AI systems that compute “personality
                    profiles” from resumes and social media profiles of job applicants.
                </p>
                <div style="margin-left: 30%;" class="elementor-element elementor-element-b45843c col-sm-6 abbr" data-id="b45843c"
                    data-element_type="container" data-settings="{&quot;content_width&quot;:&quot;full&quot;}">
                    <div class="elementor-element elementor-element-fcb6ec2 elementor-widget elementor-widget-image"
                        data-id="fcb6ec2" data-element_type="widget" data-widget_type="image.default">
                        <div class="elementor-widget-container">
                            <!--image link to be replaced below in the quotes after src= -->
                            <img src="1.png" style="max-width:300px;" alt="" data-lazy-loaded="1"
                                sizes="(max-width: 500px) 100vw, 500px" loading="eager">
                        </div>
                    </div>
                </div>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                <h2>What we’ve been up to:</h2>
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    <b>RAI Summer Research Program</b>
                </p>
                <div style="margin-left: 30%;" class="elementor-element elementor-element-b45843c col-sm-6 abbr center" data-id="b45843c"
                    data-element_type="container" data-settings="{&quot;content_width&quot;:&quot;full&quot;}">
                    <div class="elementor-element elementor-element-fcb6ec2 elementor-widget elementor-widget-image"
                        data-id="fcb6ec2" data-element_type="widget" data-widget_type="image.default">
                        <div class="elementor-widget-container">
                            <!--image link to be replaced below in the quotes after src= -->
                            <img src="2.png" style="max-width:300px;" alt="" data-lazy-loaded="1"
                                sizes="(max-width: 500px) 100vw, 500px" loading="eager">
                        </div>
                    </div>
                </div>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    We stand with Ukraine! Over the summer, we ran a 6-week-long summer research program on Responsible
                    AI, in collaboration with the Ukrainian Catholic University. Our 18 research fellows comprised
                    Ukrainian graduate and undergraduate students. <a
                        href="https://airesponsibly.net/2022/09/26/nyu-r-ai-summer-research-program-2022/"><span
                            style="font-weight: 400;">Read more</span></a> about the program, the final project
                    showcase, and testimonials from the fellows themselves! We are continuing this work in the Fall,
                    stay tuned for updates.</p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                <h2>What we’ve been working on: </h2>
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">

                    <a href="https://dl.acm.org/doi/10.1145/3514094.3534189"><b>Resume Format, LinkedIn URLs and Other
                            Unexpected Influences on AI Personality Prediction in Hiring: Results of an Audit
                        </b></a>
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    Alene Rhea, Kelsey Markey, Lauren D'Arinzo, Hilke Schellmann, Mona Sloane, Paul Squires, and Julia
                    Stoyanovich.
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    In 2022 AAAI/ACM Conference on AI, Ethics, and Society <b>(AIES '22).</b></p>
                <div style="margin-left: 30%;" class="elementor-element elementor-element-b45843c col-sm-6 abbr" data-id="b45843c"
                    data-element_type="container" data-settings="{&quot;content_width&quot;:&quot;full&quot;}">
                    <div class="elementor-element elementor-element-fcb6ec2 elementor-widget elementor-widget-image"
                        data-id="fcb6ec2" data-element_type="widget" data-widget_type="image.default">
                        <div class="elementor-widget-container">
                            <!--image link to be replaced below in the quotes after src= -->
                            <img src="3.png" style="max-width:300px;" alt="" data-lazy-loaded="1"
                                sizes="(max-width: 500px) 100vw, 500px" loading="eager">
                        </div>
                    </div>
                </div>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    Algorithmic personality tests are in broad use in hiring today, but
                    do they work? We sought to answer this question by interrogating the validity of algorithmic
                    personality tests that claim to estimate a job seeker’s personality based on their resume or
                    social media profile. We developed a methodology for auditing the stability of predictions made
                    by these tests. Crucially, we framed our methodology around testing the assumptions made by the
                    vendors of these tools. We used this methodology to conduct an external audit of two commercial
                    systems, </span><a href="https://humantic.ai/"><span style="font-weight: 400;">Humantic
                            AI</span></a><span style="font-weight: 400;"> and </span><a
                        href="https://www.crystalknows.com/"><span style="font-weight: 400;">Crystal</span></a><span
                        style="font-weight: 400;">, over a dataset of job applicant profiles collected through an
                        IRB-approved study. The key take-away is that both systems show instability on key facets of
                        measurement, and so cannot be considered valid testing instruments for pre-hire
                        assessment.&nbsp;
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    <a href="https://airesponsibly.net/2022/09/28/personality-prediction-ai-for-hiring/"><span
                            style="font-weight: 400;">Read more</span></a><span style="font-weight: 400;"> about our
                        audit, and watch a 15-minute video for a summary of our methods and findings.&nbsp; And take a
                        look at press coverage of these results in </span><a
                        href="https://www.forbes.com/sites/drnancydoyle/2022/10/11/artificial-intelligence-is-dangerous-for-disabled-people-at-work-4-takeaways-for-developers-and-buyers/?sh=77ab36af35d3"><span
                            style="font-weight: 400;">Forbes</span></a><span style="font-weight: 400;"> and </span><a
                        href="https://www.hrdive.com/news/as-nyc-restricts-ai-in-hiring-next-steps-remain-cloudy/633576/"><span
                            style="font-weight: 400;">HR Drive</span></a>
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                <h3 class="elementor-heading-title elementor-size-default"><a
                        href="https://dl.acm.org/doi/10.1145/3531146.3533090"><b>It’s Just Not That Simple: An Empirical
                            Study of the Accuracy-Explainability Trade-off in Machine Learning for Public Policy</b></a>
                </h3>
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    Andrew Bell, Ian Solano-Kamaiko, Oded Nov, and Julia Stoyanovich
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    In 2022 ACM Conference on Fairness, Accountability, and Transparency (<a
                        href="https://facctconference.org/2022/"><b>FAccT ’22</b></a>
                </p>
                <div style="margin-left: 30%;" class="elementor-element elementor-element-b45843c col-sm-6 abbr" data-id="b45843c"
                    data-element_type="container" data-settings="{&quot;content_width&quot;:&quot;full&quot;}">
                    <div class="elementor-element elementor-element-fcb6ec2 elementor-widget elementor-widget-image"
                        data-id="fcb6ec2" data-element_type="widget" data-widget_type="image.default">
                        <div class="elementor-widget-container">
                            <!--image link to be replaced below in the quotes after src= -->
                            <img src="4.png" style="max-width:300px;" alt="" data-lazy-loaded="1"
                                sizes="(max-width: 500px) 100vw, 500px" loading="eager">
                        </div>
                    </div>
                </div>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    There is a debate among machine learning researchers and practitioners about the nature – and even
                    the existence – of the accuracy-explainability trade-off. Is it the case that accuracy and
                    explainability are inversely related, and, therefore, that black-box models should be used whenever
                    accuracy is important? Or is it the case that the trade-off rarely exists, and so interpretable
                    models should be preferred in most cases? In this project, we looked at the relationship between
                    accuracy and explainability in two public policy contexts. We neither observed a direct trade-off
                    between accuracy and explainability nor found interpretable models to be superior in terms of
                    explainability. It’s just not that simple!
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    <b>Fairness in Ranking </b><a href="https://dl.acm.org/doi/10.1145/3533379"><b>Part I: Score-based
                            Ranking</b></a>&nbsp;
                    <br>
                    <b>Fairness in Ranking </b><a href="https://dl.acm.org/doi/10.1145/3533380"><b>Part II:
                            Learning-to-Rank and Recommender Systems</b></a>
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    Meike Zehlike, Ke Yang, and Julia Stoyanovich
                    <br>
                    In <b>ACM Computing Surveys</b> (April 2022)
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    Consider Ann, a university admissions officer who uses an algorithmic ranker to select applicants
                    from a large pool. Ann knows that applicants’ test scores and, to some extent, their grades, can
                    track a history of disadvantage in access to educational opportunities–good schools and tutoring–and
                    so a ranking based on test scores and grades can be unfair. How can Ann embed fairness requirements
                    into her selection methodology, in a world where applicants’ qualifications and backgrounds are as
                    incomparable as apples and oranges?

                </p>
                <div style="margin-left: 30%;" class="elementor-element elementor-element-b45843c col-sm-6 abbr" data-id="b45843c"
                    data-element_type="container" data-settings="{&quot;content_width&quot;:&quot;full&quot;}">
                    <div class="elementor-element elementor-element-fcb6ec2 elementor-widget elementor-widget-image"
                        data-id="fcb6ec2" data-element_type="widget" data-widget_type="image.default">
                        <div class="elementor-widget-container">
                            <!--image link to be replaced below in the quotes after src= -->
                            <img src="5.png" style="max-width:300px;" alt="" data-lazy-loaded="1"
                                sizes="(max-width: 500px) 100vw, 500px" loading="eager">
                        </div>
                    </div>
                </div>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    In a two-part survey that recently appeared in the ACM Computing Surveys, we set out to help
                    decision-makers like Ann. We developed a common narrative around the value frameworks that motivate
                    specific fairness-enhancing interventions in ranking. This allowed us to unify the mitigation
                    objectives and the algorithmic techniques for fair ranking that have been proposed in several
                    subfields of computer science. This unified view can help practitioners select a method that is
                    responsive to their fairness requirements.
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    <a href="https://eaamo.org/papers/khan-19.pdf"><b>Towards Substantive conceptions of Algorithmic
                            Fairness: Normative guidance from Equal Opportunity doctrines</b></a>
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    Falaah Arif Khan, Eleni Manis, and Julia Stoyanovich </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    In 2022 ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization (<a
                        href="https://eaamo.org"><b>EAAMO ’22</b></a>)
                </p>
                <div style="margin-left: 30%;" class="elementor-element elementor-element-b45843c col-sm-6 abbr" data-id="b45843c"
                    data-element_type="container" data-settings="{&quot;content_width&quot;:&quot;full&quot;}">
                    <div class="elementor-element elementor-element-fcb6ec2 elementor-widget elementor-widget-image"
                        data-id="fcb6ec2" data-element_type="widget" data-widget_type="image.default">
                        <div class="elementor-widget-container">
                            <!--image link to be replaced below in the quotes after src= -->
                            <img src="6.png" style="max-width:300px;" alt="" data-lazy-loaded="1"
                                sizes="(max-width: 500px) 100vw, 500px" loading="eager">
                        </div>
                    </div>
                </div>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    We all agree that fairness is not a statistical concept, but rather a philosophical and moral one.
                    But we don’t really understand the normative dimensions of fairness-enhancing interventions, and
                    don’t have a way to debate in values… or at least we didn’t, until now! In this work we use Equal
                    Opportunity doctrines from political philosophy to make explicit the value judgements embedded in
                    different fairness criteria. This framing allows us to characterize the context of decision-making
                    through the nature of opportunity being allocated, and to re-interpret the impossibility results
                    from a moral perspective: different conceptions of a fair contest are mutually incompatible when
                    people do not have fair life chances. This motivates the need for substantive framings of
                    algorithmic fairness, which we outline in the rest of the paper.
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    Read the <a href="https://dl.acm.org/doi/abs/10.1145/3551624.3555303"> full paper</a>, and watch our
                    <a href="https://www.youtube.com/watch?v=wIjcniWMElU">oral presentation</a> at ACM EAAMO.
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    <a href="https://lbynum.github.io/interactive-causal-inference/"><b>An Interactive Introduction to
                            Causal Inference</b></a>
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    <a href="https://lbynum.github.io/interactive-causal-inference/">Lucius E.J. Bynum, Falaah Arif
                        Khan, Oleksandra Konopatska, Joshua R. Loftus, and Julia Stoyanovich</a>
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    In 5th Workshop on Visualization for AI Explainability, an IEEE VIS workshop, (<a
                        href="https://visxai.io/"><b>VISxAI ’22</b></a>)&nbsp;
                </p>
                <div style="margin-left: 30%;" class="elementor-element elementor-element-b45843c col-sm-6 abbr" data-id="b45843c"
                    data-element_type="container" data-settings="{&quot;content_width&quot;:&quot;full&quot;}">
                    <div class="elementor-element elementor-element-fcb6ec2 elementor-widget elementor-widget-image"
                        data-id="fcb6ec2" data-element_type="widget" data-widget_type="image.default">
                        <div class="elementor-widget-container">
                            <!--image link to be replaced below in the quotes after src= -->
                            <img src="7.png" style="max-width:300px;" alt="" data-lazy-loaded="1"
                                sizes="(max-width: 500px) 100vw, 500px" loading="eager">
                        </div>
                    </div>
                </div>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    What is causal inference? What is a causal question? How do we answer causal questions? In this
                    interactive tutorial, we explore the basics of causal inference, and explain the role of
                    randomization in answering causal questions.&nbsp; Join us at our <a
                        href="https://lbynum.github.io/interactive-causal-inference/">Causal Inference Playground</a> to
                    first gain an intuition about causal inference without too much mathematical notation, and then dive
                    deeper into more theory and causal inference in observational settings.
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    <b><i>Events and Press Coverage</i></b>
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    Members of R/AI spoke in the press about our recent research results, and the recent developments in
                    AI regulation.&nbsp;&nbsp;</span></p>
                <div style="margin-left: 30%;" class="elementor-element elementor-element-b45843c col-sm-6 abbr" data-id="b45843c"
                    data-element_type="container" data-settings="{&quot;content_width&quot;:&quot;full&quot;}">
                    <div class="elementor-element elementor-element-fcb6ec2 elementor-widget elementor-widget-image"
                        data-id="fcb6ec2" data-element_type="widget" data-widget_type="image.default">
                        <div class="elementor-widget-container">
                            <!--image link to be replaced below in the quotes after src= -->
                            <img src="8.png" style="max-width:300px;" alt="" data-lazy-loaded="1"
                                sizes="(max-width: 500px) 100vw, 500px" loading="eager">
                        </div>
                    </div>
                </div>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    Julia Stoyanovich spoke with <a
                        href="https://www.vox.com/future-perfect/23387228/ai-bill-of-rights-white-house-artificial-intelligence-bias">Vox
                    </a> about the <a href="https://www.whitehouse.gov/ostp/ai-bill-of-rights/"><b>White House Blueprint
                            for an AI Bill of Rights</b></a>: “I was very happy to see that the Bill discusses the
                    effectiveness of AI systems prominently. Many systems that are in broad use today simply do not
                    work, in any meaningful sense of that term. They produce arbitrary results and are not subjected to
                    rigorous testing, and yet they are used in critical domains such as hiring and employment.&nbsp; We
                    need to develop a culture of rigorously specifying the criteria against which we evaluate AI
                    systems, testing systems before they are deployed, and re-testing them throughout their use to
                    ensure that these criteria are still met. And removing them from use if the systems do not
                    work.”&nbsp;&nbsp;</p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    Julia also spoke with <a
                        href="https://www.hrdive.com/news/as-nyc-restricts-ai-in-hiring-next-steps-remain-cloudy/633576/">HR
                        Drive</a> about New York City’s Local Law 144 that aims to regulate the use of automated
                    decision systems in hiring.&nbsp; She supports the law and thinks that it should be used to weed out
                    bad actors who produce and sell tools that don’t work.
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    Andrew Bell presented work on the Accuracy-Explainability trade-off at ACM FAccT in South Korea, in
                    June!
                    <br>
                    Lucius Bynum introduced the Causal Inference Playground at VISxAI, co-located with IEEE VIS
                    <br>
                    Falaah Arif Khan discussed the connections between Equality of Opportunity doctrines from political
                    philosophy and notions of algorithmic fairness at EAAMO in Washington, DC, in October.
                    <br>
                    Julia attended <a
                        href="https://makerfairerome.eu/en/event/maker-faire-rome-opening-conference-commongroundinnovation-keep-us-together/">Maker
                        Faire Rome</a> in October, and spoke about making Responsible AI synonymous with AI at the
                    Opening Conference, in a talk titled “IA responsabile: verso l’innovazione socialmente sostenibile”.
                    <a href="https://twitter.com/stoyanoj/status/1575292964083056640">Twitter</a> <a
                        href="https://www.linkedin.com/feed/update/urn:li:activity:6981060075687665664/">LinkedIn</a>&nbsp;
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                <h2>What we’re looking forward to: </h2>
                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                    <a href="https://unidir.org/events/2022-innovations-dialogue-ai-disruption-peace-and-security"><b>UN
                            Institute for Disarmament Research (UNIDIR)</b></a><b>: </b>Register to attend the UNIDIR
                    Innovations Dialogue on AI Disruption, Peace, and Security, in person in New York City or online.
                    Julia will speak in the opening panel, discussing the state of play and the future of AI. <a
                        href="https://twitter.com/UNIDIR/status/1564238047096487936">Twitter</a> <a
                        href="https://www.linkedin.com/posts/unidir_ai-id22-activity-6986334810428297216-kbj5">LinkedIn</a>

                </p>
                <p
                    style="border: 0px; margin: 0px 0px 20px; outline: 0px; vertical-align: baseline; white-space: normal;">
                <div class="elementor-widget-container">
                    <p><span style="text-decoration: underline;"><span style="font-weight: 400;">When</span></span><span
                            style="font-weight: 400;"><span style="text-decoration: underline;">:</span> October 20,
                            2022</span></p>
                    <p><span style="text-decoration: underline;"><span style="font-weight: 400;">Where</span><span
                                style="font-weight: 400;">: </span></span><a
                            href="https://www.fordfoundation.org/about/the-ford-foundation-center-for-social-justice/"><span
                                style="font-weight: 400;">Ford Foundation Center for Social Justice</span></a><span
                            style="font-weight: 400;">, 320 E 43rd St, New York, NY </span><span
                            style="font-weight: 400;">&nbsp;and online&nbsp;</span></p>
                    <p><span style="text-decoration: underline;"><span style="font-weight: 400;">RSVP</span><span
                                style="font-weight: 400;">: </span></span><a
                            href="https://forms.office.com/r/3wZNbSCi2N"><span style="font-weight: 400;">at this
                                link</span></a></p>
                    <p>&nbsp;</p>
                </div>
                </p>
                <!-- Image and text side by side ends here-->
        </div>
        </article>
    </div>
    </div>





    <!-- DO NOT EDIT ANYTHING BELOW THIS LINE-->
    <div class="publications" style="background-color: #57068c; padding: 30px;margin-top: 8rem;">
        <ol class="bibliography">
            <li>
                <div class="row">
                    <div class="col-sm-6 abbr">
                        <p><a href="mailto:responsibleai@nyu.edu">responsibleai@nyu.edu</a><br>
                            Center for Responsible AI<br>
                            370 Jay Street<br>
                            Brooklyn, NY 11201</p>
                    </div>
                    <div class="col-sm-6">
                        <div class="title"><span style="font-size: 14pt; color: #ffffff;">We are committed
                                to respecting your privacy and abide by all the practices and principles
                                outlined by New York University in its Digital Privacy Statement. For more
                                information, please review the full statement <a style="color: #ffffff;"
                                    href="https://www.nyu.edu/footer/copyright-and-fair-use/digital-privacy-statement.html"
                                    target="_blank" rel="noopener">here.&nbsp;</a></span>/div>

                            <div class="links">
                                <script type="text/javascript"
                                    src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>

                            </div>
                        </div>

                    </div>
                </div>
            </li>
        </ol>
        <div class="social">
            <div class="contact-icons">
                <a><svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" fill="currentColor"
                        class="bi bi-twitter" viewBox="0 0 16 16">
                        <path
                            d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334 0-.14 0-.282-.006-.422A6.685 6.685 0 0 0 16 3.542a6.658 6.658 0 0 1-1.889.518 3.301 3.301 0 0 0 1.447-1.817 6.533 6.533 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.325 9.325 0 0 1-6.767-3.429 3.289 3.289 0 0 0 1.018 4.382A3.323 3.323 0 0 1 .64 6.575v.045a3.288 3.288 0 0 0 2.632 3.218 3.203 3.203 0 0 1-.865.115 3.23 3.23 0 0 1-.614-.057 3.283 3.283 0 0 0 3.067 2.277A6.588 6.588 0 0 1 .78 13.58a6.32 6.32 0 0 1-.78-.045A9.344 9.344 0 0 0 5.026 15z" />
                    </svg></a>
                <a><svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" fill="currentColor"
                        class="bi bi-linkedin" viewBox="0 0 16 16">
                        <path
                            d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822 0-1.359.54-1.359 1.248 0 .694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225h2.4z" />
                    </svg></a>
            </div>
        </div>
    </div>
    <footer class="fixed-bottom">
        <div class="container mt-0"> © Copyright 2023 Center for Responsible AI. Powered by <a
                href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a
                href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener"
                target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank"
                rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com"
                target="_blank" rel="external nofollow noopener">Unsplash</a>. </div>
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"
        integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js"
        integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js"
        integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js"
        integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
    <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"
        integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
    <script defer src="/assets/js/zoom.js"></script>
    <script defer src="/assets/js/common.js"></script>
    <script type="text/javascript">window.MathJax = { tex: { tags: "ams" } };</script>
    <script defer type="text/javascript" id="MathJax-script"
        src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
    <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
        type="text/javascript">function progressBarSetup() { "max" in document.createElement("progress") ? (initializeProgressElement(), $(document).on("scroll", function () { progressBar.attr({ value: getCurrentScrollPosition() }) }), $(window).on("resize", initializeProgressElement)) : (resizeProgressBar(), $(document).on("scroll", resizeProgressBar), $(window).on("resize", resizeProgressBar)) } function getCurrentScrollPosition() { return $(window).scrollTop() } function initializeProgressElement() { let e = $("#navbar").outerHeight(!0); $("body").css({ "padding-top": e }), $("progress-container").css({ "padding-top": e }), progressBar.css({ top: e }), progressBar.attr({ max: getDistanceToScroll(), value: getCurrentScrollPosition() }) } function getDistanceToScroll() { return $(document).height() - $(window).height() } function resizeProgressBar() { progressBar.css({ width: getWidthPercentage() + "%" }) } function getWidthPercentage() { return getCurrentScrollPosition() / getDistanceToScroll() * 100 } const progressBar = $("#progress"); window.onload = function () { setTimeout(progressBarSetup, 50) };</script>
</body>

</html>