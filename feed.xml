<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://airesponsibly.net/feed.xml" rel="self" type="application/atom+xml" /><link href="https://airesponsibly.net/" rel="alternate" type="text/html" hreflang="en" /><updated>2025-02-11T01:27:19+00:00</updated><id>https://airesponsibly.net/feed.xml</id><title type="html">Welcome to the Center for Responsible AI at New York University</title><subtitle>Center for Responsible AI at New York University.
</subtitle><entry><title type="html">R/AI Newsletter - December 2024</title><link href="https://airesponsibly.net/news_events/2024/rai_newsletter_dec_2024/" rel="alternate" type="text/html" title="R/AI Newsletter - December 2024" /><published>2024-12-20T12:00:00+00:00</published><updated>2024-12-20T12:00:00+00:00</updated><id>https://airesponsibly.net/news_events/2024/rai_newsletter_dec_2024</id><content type="html" xml:base="https://airesponsibly.net/news_events/2024/rai_newsletter_dec_2024/"><![CDATA[]]></content><author><name></name></author><category term="newsletter" /><category term="newsletter" /><category term="lab" /><category term="publications" /><category term="events" /><summary type="html"><![CDATA[R/AI Newsletter - December 2024]]></summary></entry><entry><title type="html">R/AI Newsletter - January 2025</title><link href="https://airesponsibly.net/news_events/2024/rai_newsletter_jan_2025/" rel="alternate" type="text/html" title="R/AI Newsletter - January 2025" /><published>2024-12-20T12:00:00+00:00</published><updated>2024-12-20T12:00:00+00:00</updated><id>https://airesponsibly.net/news_events/2024/rai_newsletter_jan_2025</id><content type="html" xml:base="https://airesponsibly.net/news_events/2024/rai_newsletter_jan_2025/"><![CDATA[]]></content><author><name></name></author><category term="newsletter" /><category term="newsletter" /><category term="lab" /><category term="publications" /><category term="events" /><summary type="html"><![CDATA[R/AI Newsletter - January 2025]]></summary></entry><entry><title type="html">R/AI Research for Ukrainian Scholars – Fall 2024 Showcase</title><link href="https://airesponsibly.net/news_events/2024/rai_fallshowcase_december_2024/" rel="alternate" type="text/html" title="R/AI Research for Ukrainian Scholars – Fall 2024 Showcase" /><published>2024-12-11T12:30:00+00:00</published><updated>2024-12-11T12:30:00+00:00</updated><id>https://airesponsibly.net/news_events/2024/rai_fallshowcase_december_2024</id><content type="html" xml:base="https://airesponsibly.net/news_events/2024/rai_fallshowcase_december_2024/"><![CDATA[<h5><b>Join us for the upcoming Fall 2024 Responsible AI 
Research Program Showcase!</b></h5>

<p><strong>When:</strong> Friday, December 19th, 2024, 9am-11:30 EDT (GMT-4, NY, USA) / 16-18:30 EEST
(GMT+3, Ukraine)</p>

<p><strong>Where:</strong> <a href="https://nyu.zoom.us/j/97688526231">Zoom</a></p>

<p><a href="/RAIforUkraine/#">RAIforUkraine</a> is a program run by the Center for
Responsible AI at the Tandon School of Engineering at New York
University, in close collaboration with Ukrainian Catholic University
in Lviv, Ukraine.  Its goals are to help build research capacity in
Ukraine, both generally in STEM (Science, Technology, Engineering, and
Mathematics) and specifically in the critically important area of
Responsible AI, and to catalyze the integration of Ukrainian
researchers into the global research community.</p>

<p>In Fall 2024, 39 Ukrainian students mentored by 29 academic experts from
universities in the United States and Europe will present their research projects to the community. <a href="https://youtu.be/r7tBBcO1JIM">Watch previous showcases</a> to learn
more about their expecting work on algorithmic fairness,
interpretability and explainability, privacy and data protection, data
management for machine learning, causal inference, and evaluation and
benchmarking.</p>

<!-- <iframe width="933" height="525" src="https://www.youtube.com/watch?v=nt7rcNUyoJs" title="R/AI Research for Ukrainian Scholars – Fall 2024 Showcase" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> -->

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <a href="https://youtu.be/r7tBBcO1JIM">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/events/Fall2024_Showcase.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

	</a>
    </div>
</div>]]></content><author><name></name></author><category term="event" /><category term="collaboration" /><category term="RAIforUkraine" /><summary type="html"><![CDATA[R/AI Research Program]]></summary></entry><entry><title type="html">R/AI Newsletter - November 2024</title><link href="https://airesponsibly.net/news_events/2024/rai_newsletter_nov_2024/" rel="alternate" type="text/html" title="R/AI Newsletter - November 2024" /><published>2024-11-26T12:00:00+00:00</published><updated>2024-11-26T12:00:00+00:00</updated><id>https://airesponsibly.net/news_events/2024/rai_newsletter_nov_2024</id><content type="html" xml:base="https://airesponsibly.net/news_events/2024/rai_newsletter_nov_2024/"><![CDATA[]]></content><author><name></name></author><category term="newsletter" /><category term="newsletter" /><category term="lab" /><category term="publications" /><category term="events" /><summary type="html"><![CDATA[R/AI Newsletter - November 2024]]></summary></entry><entry><title type="html">2nd RAI for Ukraine Meetup with Mаriana Romanyshyn</title><link href="https://airesponsibly.net/news_events/2024/ucu-seminar2/" rel="alternate" type="text/html" title="2nd RAI for Ukraine Meetup with Mаriana Romanyshyn" /><published>2024-11-25T12:00:00+00:00</published><updated>2024-11-25T12:00:00+00:00</updated><id>https://airesponsibly.net/news_events/2024/ucu-seminar2</id><content type="html" xml:base="https://airesponsibly.net/news_events/2024/ucu-seminar2/"><![CDATA[<div class="row mt-3">
    <div class="col-sm mt-10 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/events/RAIforUkraine_Meetup2.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<p><br /></p>

<p><a href="https://ucu.edu.ua/en/">Ukrainian Catholic University</a> (UCU) launched, in collaboration with the <strong>Center for Responsible AI</strong> at NYU, a long-awaited series of meet-ups on the topic of Responsible AI.</p>

<p>The goal was to invite individuals who contribute to the advancement of responsible AI development and its practical applications. The first meeting was led by <a href="https://airesponsibly.net/people/denys/">Denys Herasymuk</a>, one of the first research fellows in the <a href="https://airesponsibly.net/RAIforUkraine/">#RAIforUkraine</a> program. Тhe second event, on November 28, will feature <a href="https://ua.linkedin.com/in/mariana-romanyshyn-b5896529">Mаriana Romanyshyn</a>, Area Tech Lead at the Ukraine-founded cloud-based typing assistant, <a href="https://www.grammarly.com/">Grammarly</a>.</p>

<h3 id="john-doe-meets-jane-doe-text-anonymization-for-responsible-natural-language-processing">John Doe meets Jane Doe: Text Anonymization for Responsible Natural Language Processing</h3>

<p><strong>Abstract:</strong> 
How can we effectively work with user-generated texts without compromising user data privacy? In this talk, we will discuss text anonymization as a responsible AI practice designed to protect sensitive user data while maintaining the usability of data for research and application purposes. We will explore text anonymization use cases, types of anonymization, implementation techniques, and anonymization benchmarks, as well as language-specific nuances of text anonymization. With this talk, my goal is to empower the Natural Language Processing community to embrace methodologies that balance innovation with privacy, fostering a data landscape that is not only advanced but also ethically sound.</p>

<p>A big thank you to <strong>Tetiana Zakharchenko</strong> for co-hosting and organizing the event!</p>

<p>The meet-up is set for <strong>November 28 at 6:00 PM in Kyiv and online</strong>.</p>

<p>Event details and registration at <a href="https://lnkd.in/enXqvxii">https://lnkd.in/enXqvxii</a></p>

<p><br />
<br /></p>]]></content><author><name></name></author><category term="seminar" /><category term="event" /><category term="RAIforUkraine" /><summary type="html"><![CDATA[As part of the RAI for Ukraine program, Ukrainian Catholic University (UCU) launched a series of online and in-person meet-ups, in collaboration with the **Center for Responsible AI** at NYU. Тhe second event, on November 28, will feature **Mаriana Romanyshyn, Area Tech Lead @Grammarly**. See event details here.]]></summary></entry><entry><title type="html">RAI for Ukraine Meetup Series @UCU</title><link href="https://airesponsibly.net/news_events/2024/ucu-seminars/" rel="alternate" type="text/html" title="RAI for Ukraine Meetup Series @UCU" /><published>2024-11-19T12:00:00+00:00</published><updated>2024-11-19T12:00:00+00:00</updated><id>https://airesponsibly.net/news_events/2024/ucu-seminars</id><content type="html" xml:base="https://airesponsibly.net/news_events/2024/ucu-seminars/"><![CDATA[<div class="row mt-3">
    <div class="col-sm mt-10 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/events/RAIforUkraine_Meetup1.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<p><br /></p>

<p><a href="https://ucu.edu.ua/en/">Ukrainian Catholic University</a> (UCU) launched, in collaboration with the <strong>Center for Responsible AI</strong> at NYU, a long-awaited series of meet-ups on the topic of Responsible AI.</p>

<p>The goal was to invite individuals who contribute to the advancement of responsible AI development and its practical applications. The first meeting was led by <a href="https://airesponsibly.net/people/denys/">Denys Herasymuk</a>, one of the first research fellows in the <a href="https://airesponsibly.net/RAIforUkraine/">#RAIforUkraine</a> program. He shared his personal experiences along with the findings from his research, which he conducted in collaboration with his mentors.</p>

<h3 id="responsible-approaches-to-missing-value-imputation-and-model-selection-in-machine-learning">Responsible Approaches to Missing Value Imputation and Model Selection in Machine Learning</h3>

<p><strong>Abstract:</strong> 
The talk covers my experience in the “RAI for Ukraine” program and highlights our research on responsible AI, focusing on advancements aimed at ensuring the stability and fairness of machine learning models. I will begin by sharing key insights and accomplishments from my time in the program, followed by a brief introduction to model stability and uncertainty quantification. Next, I will highlight the challenges of incorporating these dimensions of model performance into the model selection process. Building on this foundation, I will introduce our comprehensive software library for model auditing and responsible model selection, called Virny, along with an interactive tool called VirnyView. Finally, I will present our Shades-of-Null benchmark for responsible missing value imputation. This large-scale empirical study, involving 23,940 experimental pipelines, provides a comprehensive and rigorous evaluation of various families of imputation methods on a wide range of evaluation metrics, in plausible and socially meaningful missingness scenarios.</p>

<p>The talk is based on two papers:</p>
<ul>
  <li>Denys Herasymuk, Falaah Arif Khan, and Julia Stoyanovich: <a href="https://dl.acm.org/doi/10.1145/3626246.3654738">Responsible Model Selection with Virny and VirnyView</a> (SIGMOD’24);</li>
  <li>Falaah Arif Khan, Denys Herasymuk, Nazar Protsiv, Julia Stoyanovich: <a href="https://arxiv.org/abs/2409.07510">Still More Shades of Null: A Benchmark for Responsible Missing Value Imputation</a> (working paper).</li>
</ul>

<p>A big thank you to <strong>Tetiana Zakharchenko</strong> for co-hosting and organizing the event!</p>

<p>The next meet-up is set for <strong>November 28 at 6:00 PM in Kyiv</strong>, and it will feature <strong>Mariana Romanyshyn</strong>, Area Tech Lead at <strong>Grammarly</strong>. Stay tuned for further details!</p>

<p><br />
<br /></p>]]></content><author><name></name></author><category term="seminar" /><category term="event" /><category term="RAIforUkraine" /><summary type="html"><![CDATA[As part of the RAI for Ukraine program, Ukrainian Catholic University (UCU) launched a series of online and in-person meet-ups, in collaboration with the **Center for Responsible AI** at NYU. The first event featured Denys Herasymuk, one of the first **RAI for Ukraine Research Fellows**, who shared his personal experience as well as the results of his research. The event attracted a strong turnout!]]></summary></entry><entry><title type="html">R/AI Newsletter - October 2024</title><link href="https://airesponsibly.net/news_events/2024/rai_newsletter_oct_2024/" rel="alternate" type="text/html" title="R/AI Newsletter - October 2024" /><published>2024-10-30T12:00:00+00:00</published><updated>2024-10-30T12:00:00+00:00</updated><id>https://airesponsibly.net/news_events/2024/rai_newsletter_oct_2024</id><content type="html" xml:base="https://airesponsibly.net/news_events/2024/rai_newsletter_oct_2024/"><![CDATA[]]></content><author><name></name></author><category term="newsletter" /><category term="newsletter" /><category term="lab" /><category term="publications" /><category term="events" /><summary type="html"><![CDATA[R/AI Newsletter - October 2024]]></summary></entry><entry><title type="html">R/AI Seminar Series – Steven Euijong Whang</title><link href="https://airesponsibly.net/news_events/2024/talk_steven_whang/" rel="alternate" type="text/html" title="R/AI Seminar Series – Steven Euijong Whang" /><published>2024-10-30T12:00:00+00:00</published><updated>2024-10-30T12:00:00+00:00</updated><id>https://airesponsibly.net/news_events/2024/talk_steven_whang</id><content type="html" xml:base="https://airesponsibly.net/news_events/2024/talk_steven_whang/"><![CDATA[<div class="row mt-3">
    <div class="col-sm mt-10 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/events/Steven-Whang.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<p><br /></p>

<p>Professor <a href="https://stevenwhang.com">Steven Euijong Whang</a> visited NYU R/AI on October 30, 2024, and gave a talk on his recent work.</p>

<h4 id="recent-advances-in-data-centric-responsible-ai-and-the-nyu-kaist-collaboration"><strong>Recent Advances in Data-centric Responsible AI and the NYU-KAIST Collaboration</strong></h4>

<p><strong>Abstract:</strong> Data-centric Responsible AI is becoming critical as AI is widely used in our everyday lives. In addition to improving a model’s accuracy, it is important to improve other aspects including fairness, robustness, privacy, explainability, value alignment, and more. These objectives not only need to be satisfied during model training, but in all steps of machine learning starting from the data. In this seminar, I will talk about three recent works from our lab towards this goal: (1) Falcon: fair active learning for data labeling (VLDB’24), (2) RC-Mixup: robust data augmentation for regression tasks (KDD’24), and (3) ERBench: an LLM hallucination benchmark using relational databases (NeurIPS’24 Spotlight). I will also introduce our recent Global AI Frontier Lab collaboration with NYU under the project titled “AI Guardians: Development of Robust, Controllable, and Unbiased Trustworthy AI Technology”.</p>

<p><strong>Speaker’s bio:</strong> <a href="https://stevenwhang.com">Steven Euijong Whang</a> is an associate professor with tenure at KAIST EE and AI and leads the Data Intelligence Lab. His research interests include Responsible AI and Data-centric AI. He is an Associate Editor of VLDB 2025, IEEE TKDE (2023-25), and IEEE Data Eng. Bulletin (2023-24), and an Area Chair of ICLR 2025. Previously he was a Research Scientist at Google Research and co-developed the data infrastructure of the TensorFlow Extended (TFX) machine learning platform. Steven received his Ph.D. in computer science in 2012 from Stanford University. He was a Kwon Oh-Hyun Endowed Chair Professor (2020-2023) and received a Google AI Focused Research Award (2018, the first in Asia).</p>

<p><br />
<br /></p>]]></content><author><name></name></author><category term="seminar" /><summary type="html"><![CDATA[R/AI Seminar Series]]></summary></entry><entry><title type="html">R/AI Seminar Series – Mykola Pechenizkiy</title><link href="https://airesponsibly.net/news_events/2024/talk_mykola_pechenizkiy/" rel="alternate" type="text/html" title="R/AI Seminar Series – Mykola Pechenizkiy" /><published>2024-10-22T12:00:00+00:00</published><updated>2024-10-22T12:00:00+00:00</updated><id>https://airesponsibly.net/news_events/2024/talk_mykola_pechenizkiy</id><content type="html" xml:base="https://airesponsibly.net/news_events/2024/talk_mykola_pechenizkiy/"><![CDATA[<div class="row mt-3">
    <div class="col-sm mt-10 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/events/Mykola-Pechenizkiy.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<p><br /></p>

<p>Professor <a href="https://mpechen.win.tue.nl/">Mykola Pechenizkiy</a> visited NYU R/AI on October 22, 2024, and gave a talk on his recent work.</p>

<h4 id="benchmarking-and-reasoning-about-fairness-in-machine-learning"><strong>Benchmarking and Reasoning about Fairness in Machine Learning</strong></h4>

<p><strong>Abstract:</strong> Machine learning (ML), including fairness-aware machine learning (fairML) is often formulated as an optimization problem–we search through the space of many possible models for some better ones. Benchmarking has been driving lots of progress in modern ML by facilitating efficient trial-and-error. Benchmarking is also one of the main means of measuring success in fairML literature. While many fairness metrics and fairML approaches that account for them have been proposed some of the basic questions remain open: Do we truly understand what fairML is optimizing for? Are there exceptions to the Goodhart’s Law? Does the end justify the means?</p>

<p>In his talk, Mykola reflected on these questions with a quest not only to develop better benchmarking of/for fairML, but also to put more efforts into the development of methods and tools for auditing fairML solutions, enabling different stakeholders to better understand and reason about how a fairML model generates predictions and where the potential unwanted biases come from.</p>

<p><strong>Speaker’s bio:</strong> Mykola Pechenizkiy is a Full Professor at the department of Mathematics and Computer Science, Eindhoven University of Technology (TU/e), where he holds the Data Mining Chair. His core expertise and research interests are in predictive analytics and knowledge discovery from evolving data, and in their application to real-world problems in industry, medicine and education. At the Data Science Center Eindhoven, he leads the Customer Journey interdisciplinary research program aiming at developing techniques for informed and responsible analytics. Mykola Pechenizkiy received his PhD from the Computer Science and Information Systems department at the University of Jyväskylä, Finland in 2005. In addition to his work at TU/e, he is an Adjunct Professor in Data Mining for Industrial Applications at the Department of Mathematical Information Technology at the University of Jyväskylä.</p>

<p><br />
<br /></p>]]></content><author><name></name></author><category term="seminar" /><summary type="html"><![CDATA[R/AI Seminar Series]]></summary></entry><entry><title type="html">R/AI Newsletter - September 2024</title><link href="https://airesponsibly.net/news_events/2024/rai_newsletter_sep_2024/" rel="alternate" type="text/html" title="R/AI Newsletter - September 2024" /><published>2024-09-28T12:00:00+00:00</published><updated>2024-09-28T12:00:00+00:00</updated><id>https://airesponsibly.net/news_events/2024/rai_newsletter_sep_2024</id><content type="html" xml:base="https://airesponsibly.net/news_events/2024/rai_newsletter_sep_2024/"><![CDATA[]]></content><author><name></name></author><category term="newsletter" /><category term="newsletter" /><category term="lab" /><category term="publications" /><category term="events" /><summary type="html"><![CDATA[R/AI Newsletter - September 2024]]></summary></entry></feed>