---
layout: page
permalink: /research/
title: Research
description: Publications by categories in reversed chronological order. generated by jekyll-scholar.
years: [2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015]  # replace with your own years
years_priv: [2023, 2022, 2020, 2018, 2017]  # replace with your own years
years_rank: [2023, 2022, 2021, 2019, 2018, 2017, 2016, 2015]  # replace with your own years
nav: false
nav_order: 2
---
Here you can dive into the heart of our work at the Center for Responsible AI -- our research. 

Our ongoing investigations are organized around several major themes:
[data-centric AI and responsible data management](#data-centric),
[resonsible AI education and training](#education),
[explainability](#explainability), [algorithmic fairness](#fairness),
[AI policy and regulation](#policy), [privacy and data
protection](#privacy), and [responsible ranking design](#ranking).

Below, you will find an extensive compilation of our academic
publications and software artifacts, providing a window into our
scholarly contributions. Each entry includes an external link to the
full text of the paper for a comprehensive understanding.

In addition, you can explore our ongoing [technology policy](/policy) and
[education](/education) projects, complete with detailed descriptions and direct
links to the project repositories. We hope that this collection of
resources will serve as a valuable tool for researchers, students, and
the broader community to engage with our work.

<!-- _pages/publications.md -->
<div class="publications">

  <h2 class="category" id="data-centric">Data-centric AI and
responsible data management</h2> Incorporating ethics and legal
compliance into data-driven algorithmic systems has been attracting
significant attention from the computing research community, most
notably under the umbrella of fair and interpretable machine
learning. While important, much of this work has been limited in scope
to the last mile of data analysis and has disregarded both the
systemâ€™s design, development, and use life cycle (What are we
automating and why? Is the system working as intended?  Are there any
unforeseen consequences post-deployment?) and the data life cycle
(Where did the data come from? How long is it valid and
appropriate?). Our work on data-centric responsible AI and on
responsible data management is based on the observation that the
decisions we make during data collection and preparation profoundly
impact the robustness, fairness, and interpretability of the systems
we build. 

  <!-- Add your category specific text ahere -->
  {% for y in page.years %}
    <h2 class="year">{{y}}</h2>
    {% bibliography -f papers -q @*[year={{y}} && keywords ^= *data]* %}
  {% endfor %}

  <h2 class="category" id="education">Education</h2>
Insert a blurb about education here.
  <!-- Add your category specific text here -->
  {% for y in page.years %}
    <h2 class="year">{{y}}</h2>
    {% bibliography -f papers -q @*[year={{y}} && keywords ^= *edu ]* %}
  {% endfor %}

  <h2 class="category" id="explainability">Explainability</h2>
  Insert a blurb about explainability here.
  <!-- Add your category specific text here -->
  {% for y in page.years %}
    <h2 class="year">{{y}}</h2>
    {% bibliography -f papers -q @*[year={{y}} && keywords ^= *explainability]* %}
  {% endfor %}

  <h2 class="category" id="fairness">Fairness</h2>
  Insert a blurb about fairness here.
  <!-- Add your category specific text here -->
  {% for y in page.years %}
    <h2 class="year">{{y}}</h2>
    {% bibliography -f papers -q @*[year={{y}} && keywords ^= *fairness && keywords ^= *fair]* %}
  {% endfor %}

  <h2 class="category" id="policy">Policy</h2>
  Insert a blurb about privacy here.
  <!-- Add your category specific text here -->
  {% for y in page.years %}
    <h2 class="year">{{y}}</h2>
    {% bibliography -f papers -q @*[year={{y}} && keywords ^= *policy]* %}
  {% endfor %}
  
  <h2 class="category" id="privacy">Privacy</h2>
  Insert a blurb about privacy here.
  <!-- Add your category specific text here -->
  {% for y in page.years_priv %}
    <h2 class="year">{{y}}</h2>
    {% bibliography -f papers -q @*[year={{y}} && keywords ^= *privacy && keywords ^= *priv] %}
  {% endfor %}

  <h2 class="category" id="ranking">Ranking</h2> One kind of algorithm
  that is at once especially obscure, powerful, and common is the
  ranking algorithm. Algorithms rank individuals to determine credit
  worthiness, desirability for college admissions and employment, and
  compatibility as dating partners. They encode ideas of what counts
  as the best schools, neighborhoods, and technologies. Despite their
  importance, we actually can know very little about why one person
  was ranked higher than another in a dating app, or why one school
  has a better rank than that one. This is true even if we have access
  to the ranking algorithm, for example, if we have complete knowledge
  about the factors used by the ranker and their relative weights, as
  is the case for US News ranking of colleges.  We have been working
  on several aspects of responsible ranking design and use, including
  fairness, transparency and interpretability, and stability.

  <!-- Add your category specific text here -->
  {% for y in page.years_rank %}
    <h2 class="year">{{y}}</h2>
    {% bibliography -f papers -q @*[year={{y}} && keywords ^= *ranking && keywords ^= *rank] %}
  {% endfor %}

</div>